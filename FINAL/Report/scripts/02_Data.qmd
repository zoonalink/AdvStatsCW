---
title: "Chemical Sample Classification Report"
subtitle: "Data Preparation"
author: "Petter LÃ¶vehagen"
date: "09 May 2023"

RVersion: 3.6.0 
RStudio: 2023.03.0+386 Cherry Blossom Release
Platform: "x86_64-w64-mingw32/x64 (64-bit)"
OS: "Windows 11 SE"

format: 
  docx: default
  html:
    toc: true
    toc-depth: 3
    toc-title: "Contents"
    toc-location: left
    code-fold: true
    code-line-numbers: true
    theme: spacelab
    html-math-method: mathjax
    highlight: "tango"
    #css: "../data/custom.css"
prefer-docx: true
lang: "en-GB"
bibliography: "../data/AS_CW_References.bib"
csl: "../data/harvard-university-of-the-west-of-england.csl"

knitr:
  opts_chunk:
    include: false
    tidy: true
    echo: false
    warning: false
    message: false
    error: true
    fig.align: 'left'
    out.width: '90%'
    fig.width: 6
    fig.height: 4
---

```{r data_packages}
# load/install R packages/libraries
# set seed
# load flextable defaults
# see R file for details
set.seed(567)
file = "data"
# load/install R packages/libraries
source("R/chem_report_load.R")

```

```{r inspect_data}

# load csv file
chem_data <- read.csv("../data/5976423.csv")

# display first rows
head(chem_data)

# check dimensions of df
dim(chem_data)
```

## Data {#sec-data}

The supplied dataset contains `r nrow(chem_data)` samples, each with `r ncol(chem_data)-1` measurements.

The analysis team was not supplied with information about the data, e.g.:

-   what is measured
-   variable importance, interactions
-   measurement information: scale, units, reliability

Therefore, variables are treated equally and without bias. Decisions are made on statistical grounds and stated assumptions.

<br>
<br>

::: callout-tip
## Tip

Additional domain-specific contextual information about the data could result in alternative modelling decisions and outcomes.
:::

<br>
<br>

### Missing data {#sec-missing-data}

```{r missing_check}
# check for missing data

# total na in dataset
total_na<-sum(is.na(chem_data))

# as percentage
pct_na<-round(mean(is.na(chem_data)) * 100,2)

# results
total_na
pct_na
```

```{r missing_summaries}

# data frame with only rows with missing data
missing_rows <- chem_data[apply(chem_data, 1, function(row) any(is.na(row))), ]

# missing rows data frame
#print(missing_rows)

# dimensions of missing rows
#dim(missing_rows)

# summarise missing values per column 
na_counts <- colSums(is.na(missing_rows))
  
# calculate percentage of missing values per variable
na_percent <- round(na_counts/nrow(chem_data)*100, 2)

# summarise missing values by label
na_summary <- chem_data %>%
  group_by(label) %>%
  summarize_all(~ sum(is.na(.)))

# total observations
total_obs <- nrow(chem_data)

# df with row sums
row_sums <- data.frame(Label = na_summary$label, 
                        Count = rowSums(na_summary[,-1]),
                        Percentage = round(rowSums(na_summary[,-1])/total_obs * 100, 2))

# class (label) with max by percent, count
max_label_pct <- row_sums$Label[which.max(row_sums$Percentage)]
max_label_cnt <- row_sums$Label[which.max(row_sums$Count)]

# flextable for docx
missing_by_var <- data.frame(Variable = names(na_counts), Count = na_counts, Percentage = na_percent)

# missing by variable
FT_missing_by_var <- flextable(missing_by_var)

# missing by varis (top 5)
FT_top_missing_vars <- missing_by_var |>
  arrange(desc(Count)) |>
  head(5) |>
  flextable() |>
  autofit() |>
  bold(j=1) 


#FT_top_missing_vars <- align(FT_top_missing_vars, align = "left")

# missing table
FT_missing_table <- flextable(missing_rows)
#FT_missing_table

```

```{r missing_naniar}

# exploring missingness with naniar package

# visualise missing pattern
vis_miss(chem_data)

# visualise missing pattern
gg_miss_var(chem_data)

# visualise with facet
facet_plot <- gg_miss_fct(chem_data, fct = label)
facet_plot
# pairwise correlation between missingness
upset_plot <-gg_miss_upset(chem_data)
upset_plot

# amount and percentage missing for each variable
miss_var<-miss_var_summary(chem_data)

# amount and percentage missing for each observation
miss_case<-miss_case_summary(chem_data)

# var with most missing
most_missing_var <- miss_var %>%
  arrange(desc(n_miss)) %>%
  slice(1) %>%
  pull(variable)
most_missing_var


```

Before proceeding with [Exploratory Data Analysis](#sec-exploratory-data-analysis), it is important to explore `missingness`. Some classification models assume **no** missing data, and depending on the amount, prevalence and pattern, different assumptions and techniques are appropriate.

Data is assumed to be 'missing at random' (MAR) - that is, the probability of `missingness` only depends on *observed* variables. 

<!--# Missingness may require additional analysis as a future datasets may not be suited to discarding rows with missing values.  It is assumed that the dataset is 'missing at random although this should be confirmed to ensure that assumptions hold.  -->

<!--# The mcar_test() from the `naniar` package has been run and it leads us to reject the null hypothesis that the data is `missing completely at random`.  Additional tests and explorations could be employed to check`missing at random` -->

```{r mcar}
# missing completely at random
# results (statistic = 416, p < 0.05) lead to rejecting H0 that data is MCAR and accepting alternative that data is not MCAR.
mcar_test(chem_data)


```

`r case_when(pct_na <= 5 ~ paste0("The sample has ",total_na," rows with at least one missing value, which is ",pct_na,"% of the entire dataset. Given the minute amount, rows with missing values will be removed."), pct_na > 5 ~ paste0("The sample has ",total_na," rows with at least one missing value, which is ",pct_na,"% of the entire dataset. As there are more missing values than the 5% threshold, how to handle missing data needs further consideration.") )`

```{r vis_miss, echo=FALSE, include=FALSE,message=FALSE, warning=FALSE, fig.align='left'}
#| fig-alt: "Summary Visualisation of Missing Data"
#| label: fig-missData
#| fig-cap: "Visualised Missing Data"


# visualise missing pattern
vis_miss(chem_data)
```

<!--# If the missing data is not MAR - that is, it depends on *unobserved* variables, there are more appropriate  methods like maximum likelihood imputation. 

Unobserved influences for these measurements could include sample purity/quality, sample handling, or   measurement/equipment discrepancies.

*Imputation* often introduces bias into the analysis by violating method assumptions, or the imputed values differ significantly from true missing values. -->

<br>

::: callout-caution
The client should consider:

-   Concerns regarding missing data
-   Consistency measurements (equipment, staff, facilities, chemicals, etc.)
-   Reasons for missing data? Mitigation?
-   Can missing data be collected retrospectively?
-   Likely amount of missing data in the future?
:::

<br>

#### Missing value details by class and variable {#sec-missing-value-details-by-class-and-variable}

```{r var_missing_sentence, echo=FALSE, results='asis'}
# vars with missing data
missingVars <- miss_var_which(chem_data)
# how many variables with missing data
missingLen <- length(missingVars)

# initialise output variable
output <- ""

# ifelse to print different output depending on how many variables with missing data. 
if (missingLen == 0) {
  output <- "This sample has no variables with missing values."
} else if (missingLen == 1) {
  output <- paste0("In this sample, ", missingVars, " is the only variable with missing data.")
} else if (missingLen < 6) {
  # create a character vector of the missing variables, with commas between each item except for the last
  missingVars_string <- paste(missingVars[-length(missingVars)], collapse = ", ")
  # Add "and" to the end of the character vector
  missingVars_string <- paste0(missingVars_string, " and ", missingVars[length(missingVars)])
  # Print the sentence
  output <- paste0("In this sample, the following variables have missing data: ", missingVars_string, ".")
} else {
  output <- paste0("This dataset has ", missingLen, " variables with missing data. The five variables with the most missing data are:")
  
}

# # Print the output variable
# cat(output)

```

`r output`

```{r print_FT_top_missing_vars, include=TRUE, echo=FALSE, results='asis'}
#| tbl-cap: "Top 5 Variables with missing data, by count"
#| tbl-cap-location: bottom
#| tbl-alt: "Table with top five variables with most missing data"
#| tab.id: tbl-top5missing
if (missingLen >= 6) {
  FT_top_missing_vars
}
```


Variable `r most_missing_var` has the most missing values with `r miss_var[which.max(miss_var$n_miss), "n_miss"]`, accounting for `r max(miss_var$pct_miss)`% of this variable's data.

No single sample has more than `r max(miss_case$n_miss)` missing value(s). This means that, at most, a sample is missing `r round(max(miss_case$pct_miss), 2)`% of its data.

<!--# The upset plot below shows the five variables with the most missing values and confirms that no sample is missing data from more than one variable.-->

```{r upset_plot, include=TRUE, echo=FALSE, message = FALSE, tab.align='left', fig.alt="Upset plot of missing data"}
#| label: fig-upsetplot
#| fig-cap: "Upset plot of missing data"

# call upset plot
upset_plot
```

Label `r max_label_pct` has the most missing data with `r max(row_sums$Percentage)`%.

```{r missingByLabel, echo=FALSE, include=TRUE,message=FALSE, warning=FALSE, results='asis'}
#| tbl-cap: "Missing data, grouped by chemical class (label)"
#| tbl-cap-location: bottom
#| tbl-alt: "Table with missing data, grouped by chemical class"
#| tab.id: tbl-missingbylabel


# flextable by target (label)
FT_missing_by_label <- flextable(row_sums) |>
  bold(j=1) |>
  autofit()
FT_missing_by_label



```

Patterns of `missingness` are apparent for sequential variables:  

```{r heatmapMissing, include=TRUE, echo=FALSE, message = FALSE}
#| fig-alt: "Heatmap of missing data per variable, grouped by Chemical class (label)"
#| label: fig-heatmapMiss
#| fig-cap: "Heatmap of missing data per variable, grouped by Chemical class"

facet_plot
```



::: callout-caution
`Missingness` by variables for labels:

-   X1-X4 is *only* missing for label A
-   X6, X8 are *only* missing for label B
-   X9-X12 is *only* missing for label C
-   X13-X16 are *only* missing for label D
-   X17-X19 are *only* missing for label E

Is there a relationship?
:::
<br>
<br>

### Splitting data

```{r cleandata}
clean_chem_data <- chem_data[complete.cases(chem_data), ]
#clean_chem_data
dim(clean_chem_data)
sum(is.na(clean_chem_data))
```

In order to avoid introducing bias into the process, the data is divided into subsets.  Insights from analysis are solely from the training data. 

As the data is not *perfectly* balanced between labels, it is split with 'stratification' ensuring that each partition has a representative proportion of labels.

```{r frequency, include=TRUE, echo=FALSE, message = FALSE, results='asis'}
#| tbl-cap: "Frequency Table by Class (label)"
#| tbl-cap-location: bottom
#| tbl-alt: "Frequency table grouped by chemical class"
#| tab.id: tbl-freqbyclass


# frequency table
freq<-clean_chem_data %>%
  dplyr::count(label, name = 'Frequency') %>% 
  mutate(Percent = round(Frequency / sum(Frequency[1:5])*100, 2)) 

freq |>
  flextable() |>
  autofit() |>
  bold(j=1)


```

::: callout-important
## Decision

Rows with missing data are removed.

The data is split:

-   `train` - 50% - to train the classification model
-   `validation` - 25% - to validate and tune performance of the trained model(s); to establish model generalisability
-   `test` - 25% - to evaluate the performance of the final model; only used once and kept separate
:::

<!--# The below is a function to split a dataframe into three random subsets - train, validate, test.  It takes `dataframe`, `target column` (e.g. label), `proportions` (train, validate, test - need to sum to 1), `stratify` (TRUE, FALSE whether to stratify on target column).  It is saved in a separate file -->

```{r load_df_splitter}
#load dataset splitter function
source("R/df_splitter.R")

```

```{r applySplitCleanChem}
# apply to clean_chem_data
datasets <- df_splitter(df = clean_chem_data, target_col = "label", train_prop = 0.5, val_prop = 0.25, test_prop = 0.25, stratify = TRUE)

# print the sizes of each resulting dataset
cat("train:", nrow(datasets$train), "\n")
cat("validation:", nrow(datasets$val), "\n")
cat("test:", nrow(datasets$test), "\n\n\n")

# check that the proportions of the target variable are similar across the three datasets
cat("Train set target variable proportions:\n", prop.table(table(datasets$train$label)), "\n\n")
cat("Validation set target variable proportions:\n", prop.table(table(datasets$val$label)), "\n\n")
cat("Test set target variable proportions:\n", prop.table(table(datasets$test$label)), "\n")

# save separate datasets
train <- datasets$train
valid <- datasets$val
test <- datasets$test

# counts
table(train$label)
table(valid$label)
table(test$label)


# save to file - access by other sections independently
write.csv(train, "../data/chem_train.csv", row.names = FALSE)
write.csv(valid, "../data/chem_valid.csv", row.names = FALSE)
write.csv(test, "../data/chem_test.csv", row.names = FALSE)

```

<!--# The above output needs to be inspected to ensure that each subset of the original dataframe is the correct size (proportion) and has the same proportions of target labels, if stratification is required. -->
