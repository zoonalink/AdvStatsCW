@book{alpaydinMachineLearning2016,
  title = {Machine {{Learning}}},
  author = {Alpaydin, Ethem},
  year = {2016},
  publisher = {{MIT Press Ltd}},
  address = {{Cambridge, Mass.}},
  isbn = {978-0-262-52951-8}
}

@misc{BBCVisualData,
  title = {{{BBC Visual}} and {{Data Journalism}} Cookbook for {{R}} Graphics},
  urldate = {2023-02-11},
  howpublished = {https://bbc.github.io/rcookbook/},
  keywords = {ggplot,R,Visualisation},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\VHB5VLUY\\rcookbook.html}
}

@article{blankersMissingDataApproaches2010,
  title = {Missing {{Data Approaches}} in {{eHealth Research}}: {{Simulation Study}} and a {{Tutorial}} for {{Nonmathematically Inclined Researchers}}},
  shorttitle = {Missing {{Data Approaches}} in {{eHealth Research}}},
  author = {Blankers, Matthijs and Koeter, Maarten W J and Schippers, Gerard M},
  year = {2010},
  month = dec,
  journal = {Journal of Medical Internet Research},
  volume = {12},
  number = {5},
  pages = {e54},
  issn = {1438-8871},
  doi = {10.2196/jmir.1448},
  urldate = {2023-03-22},
  abstract = {Background: Missing data is a common nuisance in eHealth research: it is hard to prevent and may invalidate research findings. Objective: In this paper several statistical approaches to data ``missingness'' are discussed and tested in a simulation study. Basic approaches (complete case analysis, mean imputation, and last observation carried forward) and advanced methods (expectation maximization, regression imputation, and multiple imputation) are included in this analysis, and strengths and weaknesses are discussed. Methods: The dataset used for the simulation was obtained from a prospective cohort study following participants in an online self-help program for problem drinkers. It contained 124 nonnormally distributed endpoints, that is, daily alcohol consumption counts of the study respondents. Missingness at random (MAR) was induced in a selected variable for 50\% of the cases. Validity, reliability, and coverage of the estimates obtained using the different imputation methods were calculated by performing a bootstrapping simulation study. Results: In the performed simulation study, the use of multiple imputation techniques led to accurate results. Differences were found between the 4 tested multiple imputation programs: NORM, MICE, Amelia II, and SPSS MI. Among the tested approaches, Amelia II outperformed the others, led to the smallest deviation from the reference value (Cohen's d = 0.06), and had the largest coverage percentage of the reference confidence interval (96\%). Conclusions: The use of multiple imputation improves the validity of the results when analyzing datasets with missing observations. Some of the often-used approaches (LOCF, complete cases analysis) did not perform well, and, hence, we recommend not using these. Accumulating support for the analysis of multiple imputed datasets is seen in more recent versions of some of the widely used statistical software programs making the use of multiple imputation more readily available to less mathematically inclined researchers.},
  langid = {english},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\WLQ725YN\\Blankers et al. - 2010 - Missing Data Approaches in eHealth Research Simul.pdf}
}

@article{brownChoosingRightType,
  title = {Choosing the {{Right Type}} of {{Rotation}} in {{PCA}} and {{EFA}}},
  author = {Brown, James Dean},
  langid = {english},
  keywords = {EFA,Factor Analysis,PCA},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\LMEGTBYD\\Brown - Choosing the Right Type of Rotation in PCA and EFA.pdf}
}

@book{bruntonDataDrivenScience,
  title = {Data {{Driven Science}} \& {{Engineering Machine Learning}}, {{Dynamical Systems}}, and {{Control}}},
  author = {Brunton, Steven L. and Kutz, J. Nathan}
}

@book{bruntonDataDrivenScienceEngineering2019,
  title = {Data-{{Driven Science}} and {{Engineering}}: {{Machine Learning}}, {{Dynamical Systems}}, and {{Control}}},
  shorttitle = {Data-{{Driven Science}} and {{Engineering}}},
  author = {Brunton, Steven L. and Kutz, J. Nathan},
  year = {2019},
  publisher = {{Cambridge University Press}},
  address = {{New York, NY}},
  doi = {10.1017/9781108380690},
  abstract = {Data-driven discovery is revolutionizing the modeling, prediction, and control of complex systems. This textbook brings together machine learning, engineering mathematics, and mathematical physics to integrate modeling and control of dynamical systems with modern methods in data science. It highlights many of the recent advances in scientific computing that enable data-driven methods to be applied to a diverse range of complex systems, such as turbulence, the brain, climate, epidemiology, finance, robotics, and autonomy. Aimed at advanced undergraduate and beginning graduate students in the engineering and physical sciences, the text presents a range of topics and methods from introductory to state of the art.},
  isbn = {978-1-108-42209-3},
  langid = {english},
  keywords = {Engineering,Mathematical analysis,Science},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\LVPLWK9A\\Brunton and Kutz - 2019 - Data-Driven Science and Engineering Machine Learn.pdf}
}

@misc{bruntonDataDrivenScienceEngineering2019a,
  title = {Data-{{Driven Science}} and {{Engineering}}: {{Machine Learning}}, {{Dynamical Systems}}, and {{Control}}},
  shorttitle = {Data-{{Driven Science}} and {{Engineering}}},
  author = {Brunton, Steven L. and Kutz, J. Nathan},
  year = {2019},
  month = feb,
  journal = {Cambridge Core},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/9781108380690},
  urldate = {2023-02-17},
  abstract = {Data-driven discovery is revolutionizing the modeling, prediction, and control of complex systems. This textbook brings together machine learning, engineering mathematics, and mathematical physics to integrate modeling and control of dynamical systems with modern methods in data science. It highlights many of the recent advances in scientific computing that enable data-driven methods to be applied to a diverse range of complex systems, such as turbulence, the brain, climate, epidemiology, finance, robotics, and autonomy. Aimed at advanced undergraduate and beginning graduate students in the engineering and physical sciences, the text presents a range of topics and methods from introductory to state of the art.},
  howpublished = {https://www.cambridge.org/core/books/datadriven-science-and-engineering/77D52B171B60A496EAFE4DB662ADC36E},
  isbn = {9781108380690 9781108422093},
  langid = {english},
  keywords = {DataScience,ML,stats},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\GKEBJP4Z\\Brunton and Kutz - 2019 - Data-Driven Science and Engineering Machine Learn.pdf;C\:\\Users\\zoona\\Zotero\\storage\\EGQFBHNP\\77D52B171B60A496EAFE4DB662ADC36E.html}
}

@book{changGraphicsCookbook2nd,
  title = {R {{Graphics Cookbook}}, 2nd Edition},
  author = {Chang, Winston},
  urldate = {2023-02-21},
  abstract = {This cookbook contains more than 150 recipes to help scientists, engineers, programmers, and data analysts generate high-quality graphs quickly\textemdash without having to comb through all the details of R's graphing systems. Each recipe tackles a specific problem with a solution you can apply to your own project and includes a discussion of how and why the recipe works.},
  keywords = {Graphics,R,Visualisations},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\WE5FMINX\\r-graphics.org.html}
}

@book{Chapter4MultipleImputation,
  title = {Chapter4 {{Multiple Imputation}} | {{Book}}\_{{MI}}.Knit},
  urldate = {2023-04-18},
  keywords = {Multiple Imputation},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\4PUKB3BI\\multiple-imputation.html}
}

@misc{CiteSeerX,
  title = {{{CiteSeerX}}},
  journal = {CiteSeerX},
  urldate = {2023-04-30},
  howpublished = {https://citeseerx.ist.psu.edu/doc/10.1.1.650.2473},
  langid = {english},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\WKN5JI45\\10.1.1.650.html}
}

@misc{Content,
  title = {Content},
  urldate = {2023-02-11},
  howpublished = {https://blackboard.uwe.ac.uk/uwenav/ultra/courses/\_350158\_1/cl/outline},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\AGL4ENYK\\outline.html}
}

@misc{CS231nConvolutionalNeural,
  title = {{{CS231n Convolutional Neural Networks}} for {{Visual Recognition}}},
  urldate = {2023-02-18},
  howpublished = {https://cs231n.github.io/},
  keywords = {Neural network; visual recognition; convolutional nn; knn; stochachastic gradient descent},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\EXHVBZ7E\\cs231n.github.io.html}
}

@misc{DataManagementData,
  title = {4. {{Data Management}}, {{Data Engineering}}, and {{Data Science Overview}} - {{Implementing}} a {{Smart Data Platform}} [{{Book}}]},
  urldate = {2023-02-11},
  abstract = {Chapter 4. Data Management, Data Engineering, and Data Science Overview Data Management Data management refers to the process by which data is effectively acquired, stored, processed, and applied, aiming to \ldots{} - Selection from Implementing a Smart Data Platform [Book]},
  howpublished = {https://www.oreilly.com/library/view/implementing-a-smart/9781491983492/ch04.html},
  isbn = {9781491983485},
  langid = {english},
  keywords = {Data Engineering,Data Management,Data Science},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\4USFVL5S\\ch04.html}
}

@misc{DimensionalityReductionPrincipal,
  title = {Dimensionality {{Reduction}}; {{Principal Component Analysis}} ({{PCA}})},
  urldate = {2023-02-17},
  abstract = {Data that includes many features or many different vectors can be thought of as having many dimensions. Often, it's useful to reduce those dimensions down to something more easily visualized, for compression, or to just distill the most important information from a data set (that is, information that contributes the most to the data's variance). Principal Component Analysis and Singular Value Decomposition do that.},
  langid = {english},
  keywords = {Dimension Reduction,PCA},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\UA5HM4X4\\9781787127081-video6_3.html}
}

@misc{doiSDS375,
  title = {{{SDS}} 375},
  author = {published yet DOI, Authors Affiliations Published Not},
  journal = {SDS 375},
  urldate = {2023-02-23},
  abstract = {Data Visualization in R},
  howpublished = {https://wilkelab.org/SDS375/},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\PJ466LYX\\SDS375.html}
}

@book{downeyThinkPythonHow2015,
  title = {Think Python: How to Think like a Computer Scientist},
  author = {Downey, Allen},
  year = {2015},
  edition = {Second edition},
  publisher = {{O'Reilly}},
  address = {{Sebastopol, CA}},
  isbn = {1-4919-3941-9}
}

@misc{elgabryDatabaseDatabaseDesign2018,
  title = {Database \textemdash{} {{Database Design}}: {{Conceptual Design}} ({{Part}} 4)},
  shorttitle = {Database \textemdash{} {{Database Design}}},
  author = {Elgabry, Omar},
  year = {2018},
  month = jul,
  journal = {Medium},
  urldate = {2023-02-11},
  abstract = {The conceptual design provides a high-level description that's close to the way many users perceive data.},
  howpublished = {https://medium.com/omarelgabrys-blog/database-database-modeling-conceptual-design-part-4-645545a74a4b},
  langid = {english},
  keywords = {Conceptual,Database,Database Design},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\Z2UIL4TD\\database-database-modeling-conceptual-design-part-4-645545a74a4b.html}
}

@misc{elgabryDatabaseDatabaseOptions2021,
  title = {Database \textemdash{} {{Database Options}} ({{Part}} 10)},
  author = {Elgabry, Omar},
  year = {2021},
  month = jul,
  journal = {Medium},
  urldate = {2023-02-11},
  abstract = {What are the options, and why we need to choose one over another?},
  howpublished = {https://medium.com/omarelgabrys-blog/database-database-options-part-10-380c6e4467d0},
  langid = {english},
  keywords = {Database,Database Options},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\TQC9NJWE\\database-database-options-part-10-380c6e4467d0.html}
}

@misc{elgabryDatabaseDesignLogical2021,
  title = {Database \textemdash{} {{Design}}: {{Logical Design}} ({{Part}} 6)},
  shorttitle = {Database \textemdash{} {{Design}}},
  author = {Elgabry, Omar},
  year = {2021},
  month = dec,
  journal = {Medium},
  urldate = {2023-02-11},
  abstract = {The logical design is about mapping of entities, relationships, and multi-valued attributes into a logical schema.},
  howpublished = {https://medium.com/omarelgabrys-blog/database-modeling-logical-design-part-6-af029e93cc1f},
  langid = {english},
  keywords = {Database,Database Design,Entity Model},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\5GY9DJYL\\database-modeling-logical-design-part-6-af029e93cc1f.html}
}

@misc{elgabryDatabaseDesignProcess2021,
  title = {Database \textemdash{} {{Design Process}} ({{Part}} 3)},
  author = {Elgabry, Omar},
  year = {2021},
  month = dec,
  journal = {Medium},
  urldate = {2023-02-11},
  abstract = {We'll walk through the steps to design and create a database.},
  howpublished = {https://medium.com/omarelgabrys-blog/database-design-process-part-3-7b5fafc78774},
  langid = {english},
  keywords = {Database,Database Design,Database Model},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\YSPEUAYC\\database-design-process-part-3-7b5fafc78774.html}
}

@misc{elgabryDatabaseFundamentalsPart2021,
  title = {Database \textemdash{} {{Fundamentals}} ({{Part}} 2)},
  author = {Elgabry, Omar},
  year = {2021},
  month = dec,
  journal = {Medium},
  urldate = {2023-02-11},
  abstract = {The first step towards understanding the databases (specifically relational databases) is understanding the basic features.},
  howpublished = {https://medium.com/omarelgabrys-blog/database-fundamentals-part-2-b841032243ac},
  langid = {english},
  keywords = {Database},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\M8NGIQ8X\\database-fundamentals-part-2-b841032243ac.html}
}

@misc{elgabryDatabaseIndexingTransactions2018,
  title = {Database \textemdash{} {{Indexing}}, {{Transactions}} \& {{Stored Procedures}} ({{Part}} 9)},
  author = {Elgabry, Omar},
  year = {2018},
  month = jul,
  journal = {Medium},
  urldate = {2023-02-11},
  abstract = {Optimization, Working with sensitive data, \& Re-usability.},
  howpublished = {https://medium.com/omarelgabrys-blog/database-indexing-and-transactions-part-9-a24781d429f8},
  langid = {english},
  keywords = {Database,Indexing,Transaction},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\WLJL5222\\database-indexing-and-transactions-part-9-a24781d429f8.html}
}

@misc{elgabryDatabaseIntroductionPart2021,
  title = {Database \textemdash{} {{Introduction}} ({{Part}} 1)},
  author = {Elgabry, Omar},
  year = {2021},
  month = dec,
  journal = {OmarElgabry's Blog},
  urldate = {2023-02-11},
  abstract = {Why a database, What's a database, and DBMS.},
  langid = {english},
  keywords = {Data Management,Database},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\GY3LDM9R\\database-introduction-part-1-4844fada1fb0.html}
}

@misc{elgabryDatabaseModelingEntity2021,
  title = {Database \textemdash{} {{Modeling}} : {{Entity Relationship Diagram}} ({{ERD}}) ({{Part}} 5)},
  shorttitle = {Database \textemdash{} {{Modeling}}},
  author = {Elgabry, Omar},
  year = {2021},
  month = dec,
  journal = {Medium},
  urldate = {2023-02-11},
  abstract = {A common approach to sketch the entities and their relationships.},
  howpublished = {https://medium.com/omarelgabrys-blog/database-modeling-entity-relationship-diagram-part-5-352c5a8859e5},
  langid = {english},
  keywords = {Database,Entity Model,ERD},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\Y4K7K3HE\\database-modeling-entity-relationship-diagram-part-5-352c5a8859e5.html}
}

@misc{elgabryDatabaseNormalizationPart2018,
  title = {Database \textemdash{} {{Normalization}} ({{Part}} 7)},
  author = {Elgabry, Omar},
  year = {2018},
  month = jul,
  journal = {Medium},
  urldate = {2023-02-11},
  abstract = {The process of organizing your database through a set of defined steps.},
  howpublished = {https://medium.com/omarelgabrys-blog/database-normalization-part-7-ef7225150c7f},
  langid = {english},
  keywords = {Database,normalisation},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\MEZFG6JR\\database-normalization-part-7-ef7225150c7f.html}
}

@misc{elgabryDatabaseStructuredQuery2018,
  title = {Database \textemdash{} {{Structured Query Language}} ({{SQL}}) ({{Part}} 8)},
  author = {Elgabry, Omar},
  year = {2018},
  month = jul,
  journal = {Medium},
  urldate = {2023-02-11},
  abstract = {Leverage The Power of The Structured Query Language (SQL).},
  howpublished = {https://medium.com/omarelgabrys-blog/database-structured-query-language-part-8-230a1808ec96},
  langid = {english},
  keywords = {Database,SQL},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\3X3IZADF\\database-structured-query-language-part-8-230a1808ec96.html}
}

@article{flanaganEarlywarningPredictionStudent2022,
  title = {Early-Warning Prediction of Student Performance and Engagement in Open Book Assessment by Reading Behavior Analysis},
  author = {Flanagan, Brendan and Majumdar, Rwitajit and Ogata, Hiroaki},
  year = {2022},
  month = aug,
  journal = {International Journal of Educational Technology in Higher Education},
  volume = {19},
  number = {1},
  pages = {41},
  issn = {2365-9440},
  doi = {10.1186/s41239-022-00348-4},
  urldate = {2023-03-27},
  abstract = {Digitized learning materials are a core part of modern education, and analysis of the use can offer insight into the learning behavior of high and low performing students. The topic of predicting student characteristics has gained a lot of attention in recent years, with applications ranging from affect to performance and at-risk student prediction. In this paper, we examine students reading behavior using a digital textbook system while taking an open-book test from the perspective of engagement and performance to identify the strategies that are used. We create models to predict the performance and engagement of learners before the start of the assessment and extract reading behavior characteristics employed before and after the start of the assessment in a higher education setting. It was found that strategies, such as: revising and previewing are indicators of how a learner will perform in an open ebook assessment. Low performing students take advantage of the open ebook policy of the assessment and employ a strategy of searching for information during the assessment. Also compared to performance, the prediction of overall engagement has a higher accuracy, and therefore could be more appropriate for identifying intervention candidates as an early-warning intervention system.},
  keywords = {Early warning prediction,HE,ML,Open-book assessment,Prediction,Reading behavior,Student modeling},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\T8GIK3GR\\Flanagan et al. - 2022 - Early-warning prediction of student performance an.pdf;C\:\\Users\\zoona\\Zotero\\storage\\R4B3CJY4\\s41239-022-00348-4.html}
}

@book{ForecastingPrinciplesPractice,
  title = {Forecasting: {{Principles}} and {{Practice}} (3rd Ed)},
  shorttitle = {Forecasting},
  urldate = {2023-03-28},
  abstract = {3rd edition},
  keywords = {Forecasting,Prediction,TimeSeries},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\3ZKA3ZA5\\fpp3.html}
}

@article{fraleyModelBasedClusteringDiscriminant2002,
  title = {Model-{{Based Clustering}}, {{Discriminant Analysis}}, and {{Density Estimation}}},
  author = {Fraley, Chris and Raftery, Adrian E},
  year = {2002},
  month = jun,
  journal = {Journal of the American Statistical Association},
  volume = {97},
  number = {458},
  pages = {611--631},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1198/016214502760047131},
  urldate = {2023-03-08},
  abstract = {Cluster analysis is the automated search for groups of related observations in a dataset. Most clustering done in practice is based largely on heuristic but intuitively reasonable procedures, and most clustering methods available in commercial software are also of this type. However, there is little systematic guidance associated with these methods for solving important practical questions that arise in cluster analysis, such as how many clusters are there, which clustering method should be used, and how should outliers be handled. We review a general methodology for model-based clustering that provides a principled statistical approach to these issues. We also show that this can be useful for other problems in multivariate analysis, such as discriminant analysis and multivariate density estimation. We give examples from medical diagnosis, minefield detection, cluster recovery from noisy data, and spatial density estimation. Finally, we mention limitations of the methodology and discuss recent developments in model-based clustering for non-Gaussian data, high-dimensional datasets, large datasets, and Bayesian estimation.},
  keywords = {Bayes factor,Breast cancer diagnosis,Cluster analysis,Density Estimation,Discriminant Analysis,EM algorithm,Gene expression microarray data,Markov chain Monte Carlo,Mixture model,Model-Based Clustering,Outliers,Spatial point process},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\G3VN8PRC\\Fraley and Raftery - 2002 - Model-Based Clustering, Discriminant Analysis, and.pdf}
}

@article{FreedmanDiaconisRule2022,
  title = {Freedman\textendash{{Diaconis}} Rule},
  year = {2022},
  month = jul,
  journal = {Wikipedia},
  urldate = {2023-04-30},
  abstract = {In statistics, the Freedman\textendash Diaconis rule can be used to select the width of the bins to be used in a histogram. It is named after David A. Freedman and Persi Diaconis.  For a set of empirical measurements sampled from some probability distribution, the Freedman-Diaconis rule is designed roughly to minimize the integral of the squared difference between the histogram (i.e., relative frequency density) and the density of the theoretical probability distribution. The general equation for the rule is:                                   Bin width                  =         2                                                                          IQR                              (               x               )                                                          n                                    3                                                                                  \{\textbackslash displaystyle \{\textbackslash text\{Bin width\}\}=2\textbackslash,\{\{\textbackslash text\{IQR\}\}(x) \textbackslash over \{\textbackslash sqrt[\{3\}]\{n\}\}\}\}   where                         IQR         ⁡         (         x         )                 \{\textbackslash displaystyle \textbackslash operatorname \{IQR\} (x)\}    is the interquartile range of the data and                         n                 \{\textbackslash displaystyle n\}    is the number of observations in the sample                         x         .                 \{\textbackslash displaystyle x.\}},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1101307943},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\6UWT9NXM\\Freedman–Diaconis_rule.html}
}

@book{geronHandsonMachineLearning2019,
  title = {Hands-on {{Machine Learning}} with {{Scikit-Learn}}, {{Keras}}, and {{TensorFlow}}: {{Concepts}}, {{Tools}}, and {{Techniques}} to {{Build Intelligent Systems}}},
  author = {Geron, Aurelien},
  year = {2019},
  edition = {2nd edition},
  publisher = {{O'Reilly}},
  address = {{Cambridge}},
  isbn = {978-1-4920-3261-8}
}

@book{geronHandsOnMachineLearning2022,
  title = {Hands-{{On Machine Learning}} with {{Scikit-Learn}}, {{Keras}}, and {{TensorFlow}}},
  author = {G{\'e}ron, Aur{\'e}lien},
  year = {2022},
  edition = {3rd ed.},
  publisher = {{O'Reilly Media, Inc.}},
  isbn = {978-1-09-812596-7},
  langid = {english},
  keywords = {keras,Machine Learning,scikit-learn,tensorflow}
}

@misc{GgplotFlipbook,
  title = {The Ggplot Flipbook},
  urldate = {2023-02-21},
  howpublished = {https://evamaerey.github.io/ggplot\_flipbook/ggplot\_flipbook\_xaringan.html\#1},
  keywords = {ggplot,R,visualisation},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\RYFVHGB9\\ggplot_flipbook_xaringan.html}
}

@inproceedings{ghoshOptimumChoiceNearest2006,
  title = {On Optimum Choice of k in Nearest Neighbor Classification},
  author = {Ghosh, A.},
  year = {2006},
  urldate = {2023-03-07},
  abstract = {A major issue in k-nearest neighbor classification is how to choose the optimum value of the neighborhood parameter k. Popular cross-validation techniques often fail to guide us well in selecting k mainly due to the presence of multiple minimizers of the estimated misclassification rate. This article investigates a Bayesian method in this connection, which solves the problem of multiple optimizers. The utility of the proposed method is illustrated using some benchmark data sets. \textcopyright{} 2005 Elsevier B.V. All rights reserved.},
  keywords = {Classification,KNN}
}

@book{gohelFlextableFunctionsTabular2023,
  title = {Flextable: {{Functions}} for {{Tabular Reporting}}},
  author = {Gohel, David and Skintzos, Panagiotis},
  year = {2023}
}

@book{grolemundDataScience2017,
  title = {R for {{Data Science}}},
  author = {Grolemund, Garrett and Wickham, Hadley},
  year = {2017},
  publisher = {{O'Reilly}}
}

@book{grusDataScienceScratch2019,
  title = {Data {{Science}} from {{Scratch}}: {{First Principles}} with {{Python}}},
  author = {Grus, Joel},
  year = {2019},
  edition = {2nd edition},
  publisher = {{O'Reilly}},
  address = {{Cambridge}},
  isbn = {978-1-4920-4110-8}
}

@book{guttagIntroductionComputationProgramming2016,
  title = {Introduction to Computation and Programming Using {{Python}}: With Application to Understanding Data},
  author = {Guttag, John},
  year = {2016},
  edition = {Second edition},
  publisher = {{The MIT Press}},
  address = {{Cambridge, Massachusetts}},
  isbn = {0-262-52962-9}
}

@misc{HandsonPythonTutorial,
  title = {Hands-on {{Python Tutorial}} \textemdash{} {{Hands-on Python Tutorial}} for {{Python}} 3.1},
  howpublished = {https://anh.cs.luc.edu/python/hands-on/3.1/handsonHtml/index.html\#}
}

@book{hastieElementsStatisticalLearning2009,
  title = {The {{Elements}} of {{Statistical Learning}}},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  year = {2009},
  edition = {2nd edition}
}

@article{haytonFactorRetentionDecisions2004,
  title = {Factor {{Retention Decisions}} in {{Exploratory Factor Analysis}}: A {{Tutorial}} on {{Parallel Analysis}}},
  shorttitle = {Factor {{Retention Decisions}} in {{Exploratory Factor Analysis}}},
  author = {Hayton, James C. and Allen, David G. and Scarpello, Vida},
  year = {2004},
  month = apr,
  journal = {Organizational Research Methods},
  volume = {7},
  number = {2},
  pages = {191--205},
  publisher = {{SAGE Publications Inc}},
  issn = {1094-4281},
  doi = {10.1177/1094428104263675},
  urldate = {2023-02-11},
  abstract = {The decision of how many factors to retain is a critical component of exploratory factor analysis. Evidence is presented that parallel analysis is one of the most accurate factor retention methods while also being one of the most underutilized in management and organizational research. Therefore, a step-by-step guide to performing parallel analysis is described, and an example is provided using data from the Minnesota Satisfaction Questionnaire. Recommendations for making factor retention decisions are discussed.},
  keywords = {EFA,Parallel Analysis},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\IVZU3W4X\\Hayton et al. - 2004 - Factor Retention Decisions in Exploratory Factor A.pdf}
}

@book{huntBeginnersGuidePython2019,
  title = {Beginners {{Guide}} to {{Python}} 3 {{Programming}}},
  author = {Hunt, John},
  year = {2019},
  month = aug,
  edition = {1st ed. 2019},
  publisher = {{Springer Nature Switzerland AG}},
  address = {{Cham}},
  isbn = {978-3-030-20289-7}
}

@book{idrisNumPyBeginnerGuide2015,
  title = {{{NumPy}} Beginner's Guide: Build Efficient, High-Speed Programs Using the High-Performance {{NumPy}} Mathematical Library},
  author = {Idris, Ivan},
  year = {2015},
  edition = {3rd ed},
  publisher = {{Packt Publishing}},
  address = {{Birmingham, England}},
  isbn = {1-78528-883-0}
}

@misc{IntroducingIPythonIPython,
  title = {Introducing {{IPython}} \textemdash{} {{IPython}} 3.2.1 Documentation},
  howpublished = {https://ipython.org/ipython-doc/3/interactive/tutorial.html}
}

@book{Introduction,
  title = {1. {{Introduction}}},
  urldate = {2023-02-18},
  abstract = {Chapter 1. Introduction  ``Data! Data! Data!'' he cried impatiently. ``I can't make bricks without clay.'' Arthur Conan Doyle The Ascendance of Data  We live in a world that's drowning in...},
  isbn = {978-1-4920-4112-2},
  langid = {english},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\GYPYIRD5\\ch01.html}
}

@book{jamesIntroductionStatisticalLearning2013,
  title = {An Introduction to Statistical Learning: With Applications in {{R}}},
  shorttitle = {An Introduction to Statistical Learning},
  author = {James, Gareth},
  year = {2013},
  series = {Springer Texts in Statistics},
  publisher = {{Springer}},
  address = {{New York}},
  collaborator = {Witten, Daniela and Hastie, Trevor and Tibshirani, Robert and {EBSCOhost}},
  isbn = {978-1-4614-7138-7},
  langid = {english},
  keywords = {Machine Learning,Mathematical models,Mathematical statistics,R (Computer program language),Statistics},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\UT5GXHHK\\James - 2013 - An introduction to statistical learning with appl.pdf}
}

@book{lutzProgrammingPython0000,
  title = {Programming {{Python}}},
  author = {Lutz, Mark},
  year = {0000 c},
  edition = {4th ed},
  publisher = {{O'Reilly}},
  address = {{Beijing}},
  isbn = {978-1-4493-0285-6}
}

@misc{MachineLearningHigher,
  title = {Machine Learning in Higher Education | {{McKinsey}}},
  urldate = {2023-03-26},
  howpublished = {https://www.mckinsey.com/industries/education/our-insights/using-machine-learning-to-improve-student-success-in-higher-education},
  keywords = {HE,ML},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\KARRE25U\\using-machine-learning-to-improve-student-success-in-higher-education.html}
}

@article{martinianiStructuralAnalysisHighdimensional2016,
  title = {Structural Analysis of High-Dimensional Basins of Attraction},
  author = {Martiniani, Stefano and Schrenk, K. Julian and Stevenson, Jacob D. and Wales, David J. and Frenkel, Daan},
  year = {2016},
  month = sep,
  journal = {Physical Review E},
  volume = {94},
  number = {3},
  eprint = {1603.09627},
  primaryclass = {cond-mat, physics:physics},
  pages = {031301},
  issn = {2470-0045, 2470-0053},
  doi = {10.1103/PhysRevE.94.031301},
  urldate = {2023-03-07},
  abstract = {We propose an efficient Monte Carlo method for the computation of the volumes of high-dimensional bodies with arbitrary shape. We start with a region of known volume within the interior of the manifold and then use the multistate Bennett acceptance-ratio method to compute the dimensionless free-energy difference between a series of equilibrium simulations performed within this object. The method produces results that are in excellent agreement with thermodynamic integration, as well as a direct estimate of the associated statistical uncertainties. The histogram method also allows us to directly obtain an estimate of the interior radial probability density profile, thus yielding useful insight into the structural properties of such a high-dimensional body. We illustrate the method by analyzing the effect of structural disorder on the basins of attraction of mechanically stable packings of soft repulsive spheres.},
  archiveprefix = {arxiv},
  keywords = {Cluster,Condensed Matter - Disordered Systems and Neural Networks,Condensed Matter - Soft Condensed Matter,Condensed Matter - Statistical Mechanics,Dimensionality,ML,Physics - Computational Physics},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\RHTSV59G\\Martiniani et al. - 2016 - Structural analysis of high-dimensional basins of .pdf;C\:\\Users\\zoona\\Zotero\\storage\\TL293HHM\\1603.html}
}

@misc{MBCBookWebpage,
  title = {The {{MBC}} Book Webpage},
  urldate = {2023-02-11},
  howpublished = {https://math.unice.fr/\textasciitilde cbouveyr/MBCbook/},
  keywords = {R},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\ZJEEXQKS\\MBCbook.html}
}

@book{mckinneyPythonDataAnalysis2017,
  title = {Python for Data Analysis: Data Wrangling with {{Pandas}}, {{NumPy}}, and {{IPython}}},
  author = {McKinney, Wes},
  year = {2017},
  edition = {Second edition},
  publisher = {{O'Reilly}},
  address = {{Beijing}},
  isbn = {978-1-4919-5763-9}
}

@book{mckinneyPythonDataAnalysis2017a,
  title = {Python for Data Analysis: Data Wrangling with {{Pandas}}, {{NumPy}}, and {{IPython}}},
  author = {McKinney, Wes},
  year = {2017},
  edition = {Second edition},
  publisher = {{O'Reilly}},
  address = {{Beijing}},
  isbn = {978-1-4919-5763-9}
}

@book{murphyProbabilisticMachineLearning2022,
  title = {Probabilistic {{Machine Learning}}: {{An}} Introduction},
  author = {Murphy, Kevin P.},
  year = {2022},
  publisher = {{MIT Press}},
  keywords = {Machine Learning,Probabilistic ML},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\EEWL6GCA\\Murphy - 2022 - Probabilistic Machine Learning An introduction.pdf}
}

@article{osborneWhatRotatingExploratory,
  title = {What Is {{Rotating}} in {{Exploratory Factor Analysis}}?},
  author = {Osborne, Jason W.},
  publisher = {{University of Massachusetts Amherst}},
  doi = {10.7275/HB2G-M060},
  urldate = {2023-02-11},
  abstract = {Exploratory factor analysis (EFA) is one of the most commonly-reported quantitative methodology in the social sciences, yet much of the detail regarding what happens during an EFA remains unclear. The goal of this brief technical note is to explore what "rotation" is, what exactly is rotating, and why we use rotation when performing EFAs. Some commentary about the relative utility and desirability of different rotation methods concludes the narrative.},
  langid = {english},
  keywords = {EFA,Rotation},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\EVG7DXPE\\Osborne - What is Rotating in Exploratory Factor Analysis.pdf}
}

@book{pearlCausalityModelsReasoning2000,
  title = {Causality: Models, Reasoning, and Inference},
  author = {Pearl, Judea},
  year = {2000},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  isbn = {978-0-511-80316-1}
}

@book{pedersenGgplot2ElegantGraphics,
  title = {Ggplot2: {{Elegant Graphics}} for {{Data Analysis}}},
  author = {Pedersen, Danielle Navarro, {and} Thomas Lin, Hadley Wickham},
  urldate = {2023-02-11},
  abstract = {A book created with bookdown.},
  langid = {english},
  keywords = {ggplot,R,Visualisation},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\3T6R9A9I\\ggplot2-book.org.html}
}

@book{pedersenWelcomeGgplot2,
  title = {Welcome | Ggplot2},
  author = {Pedersen, Danielle Navarro, {and} Thomas Lin, Hadley Wickham},
  urldate = {2023-03-20},
  abstract = {A book created with bookdown.},
  langid = {english},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\46SGWZJG\\Pedersen - Welcome  ggplot2.html}
}

@book{Preface,
  title = {Preface},
  urldate = {2023-02-18},
  abstract = {Preface The Machine Learning Tsunami  In 2006, Geoffrey Hinton et al. published a paper\nolinebreak\nolinebreak 1 showing how to train a deep neural network capable of recognizing handwritten digits with...},
  isbn = {978-1-09-812596-7},
  langid = {english},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\IMKTMNEF\\Preface.html}
}

@book{PrefaceSecondEdition,
  title = {Preface to the {{Second Edition}}},
  urldate = {2023-02-18},
  abstract = {Preface to the Second Edition  I am exceptionally proud of the first edition of Data Science from Scratch. It turned out very much the book I wanted it to be. But several years of developments...},
  isbn = {978-1-4920-4112-2},
  langid = {english},
  keywords = {Data Science,Machine Learning,ML},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\F26SCPLF\\preface01.html}
}

@misc{Python3TutorialPython,
  title = {Python3 {{Tutorial}}: {{Python Online Course}}},
  howpublished = {https://www.python-course.eu/python3\_course.php}
}

@misc{pythonPythonMySQLDatabase,
  title = {Python and {{MySQL Database}}: {{A Practical Introduction}} \textendash{} {{Real Python}}},
  shorttitle = {Python and {{MySQL Database}}},
  author = {Python, Real},
  urldate = {2023-02-11},
  abstract = {In this tutorial, you'll learn how to connect your Python application with a MySQL database. You'll design a movie rating system and perform some common queries on it. You'll also see best practices and tips to prevent SQL injection attacks.},
  howpublished = {https://realpython.com/python-mysql/},
  langid = {english},
  keywords = {Database,MySQL,Python},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\QVJ6PH9K\\python-mysql.html}
}

@misc{PythonTutorialPython,
  title = {The {{Python Tutorial}} \textemdash{} {{Python}} 3.6.4 Documentation},
  howpublished = {https://docs.python.org/3/tutorial/index.html}
}

@book{rajagopalanPythonDataAnalyst2020,
  title = {A {{Python}} Data Analyst's Toolkit: Learn {{Python}} and {{Python-based}} Libraries with Applications in Data Analysis and Statistics},
  author = {Rajagopalan, Gayathri},
  year = {2020},
  publisher = {{Apress}},
  address = {{New York}},
  isbn = {978-1-4842-6399-0}
}

@book{revellePsychProceduresPsychological2022,
  title = {Psych: {{Procedures}} for {{Psychological}}, {{Psychometric}}, and {{Personality Research}}},
  author = {Revelle, William},
  year = {2022}
}

@book{revellePsychProceduresPsychological2022a,
  title = {Psych: {{Procedures}} for {{Psychological}}, {{Psychometric}}, and {{Personality Research}}},
  author = {Revelle, William},
  year = {2022}
}

@book{riedererMarkdownCookbook,
  title = {R {{Markdown Cookbook}}},
  author = {Riederer, Christophe Dervieux, Emily, Yihui Xie},
  urldate = {2023-02-11},
  abstract = {This book showcases short, practical examples of lesser-known tips and tricks to helps users get the most out of these tools. After reading this book, you will understand how R Markdown documents are transformed from plain text and how you may customize nearly every step of this processing. For example, you will learn how to dynamically create content from R code, reference code in other documents or chunks, control the formatting with customer templates, fine-tune how your code is processed, and incorporate multiple languages into your analysis.},
  keywords = {Markdown,R,RMD},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\GR98LP8F\\rmarkdown-cookbook.html}
}

@misc{ScikitlearnMachineLearning,
  title = {Scikit-Learn: Machine Learning in {{Python}} \textemdash{} Scikit-Learn 0.19.1 Documentation},
  howpublished = {http://scikit-learn.org/stable/}
}

@article{shahidComparisonDistanceMeasures2009,
  title = {Comparison of Distance Measures in Spatial Analytical Modeling for Health Service Planning},
  author = {Shahid, Rizwan and Bertazzon, Stefania and Knudtson, Merril L and Ghali, William A},
  year = {2009},
  month = nov,
  journal = {BMC Health Services Research},
  volume = {9},
  pages = {200},
  issn = {1472-6963},
  doi = {10.1186/1472-6963-9-200},
  urldate = {2023-03-07},
  abstract = {Background Several methodological approaches have been used to estimate distance in health service research. In this study, focusing on cardiac catheterization services, Euclidean, Manhattan, and the less widely known Minkowski distance metrics are used to estimate distances from patient residence to hospital. Distance metrics typically produce less accurate estimates than actual measurements, but each metric provides a single model of travel over a given network. Therefore, distance metrics, unlike actual measurements, can be directly used in spatial analytical modeling. Euclidean distance is most often used, but unlikely the most appropriate metric. Minkowski distance is a more promising method. Distances estimated with each metric are contrasted with road distance and travel time measurements, and an optimized Minkowski distance is implemented in spatial analytical modeling. Methods Road distance and travel time are calculated from the postal code of residence of each patient undergoing cardiac catheterization to the pertinent hospital. The Minkowski metric is optimized, to approximate travel time and road distance, respectively. Distance estimates and distance measurements are then compared using descriptive statistics and visual mapping methods. The optimized Minkowski metric is implemented, via the spatial weight matrix, in a spatial regression model identifying socio-economic factors significantly associated with cardiac catheterization. Results The Minkowski coefficient that best approximates road distance is 1.54; 1.31 best approximates travel time. The latter is also a good predictor of road distance, thus providing the best single model of travel from patient's residence to hospital. The Euclidean metric and the optimal Minkowski metric are alternatively implemented in the regression model, and the results compared. The Minkowski method produces more reliable results than the traditional Euclidean metric. Conclusion Road distance and travel time measurements are the most accurate estimates, but cannot be directly implemented in spatial analytical modeling. Euclidean distance tends to underestimate road distance and travel time; Manhattan distance tends to overestimate both. The optimized Minkowski distance partially overcomes their shortcomings; it provides a single model of travel over the network. The method is flexible, suitable for analytical modeling, and more accurate than the traditional metrics; its use ultimately increases the reliability of spatial analytical models.},
  pmcid = {PMC2781002},
  pmid = {19895692},
  keywords = {Distance Measure,Minkowski,ML},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\2RUHHUQV\\Shahid et al. - 2009 - Comparison of distance measures in spatial analyti.pdf}
}

@book{shawLearnMorePython2018,
  title = {Learn More {{Python}} 3 the Hard Way: The next Step for New {{Python}} Programmers},
  author = {Shaw, Zed},
  year = {2018},
  publisher = {{Addison-Wesley}},
  address = {{Boston}},
  isbn = {978-0-13-412299-1}
}

@misc{shlensTutorialPrincipalComponent2014,
  title = {A {{Tutorial}} on {{Principal Component Analysis}}},
  author = {Shlens, Jonathon},
  year = {2014},
  month = apr,
  number = {arXiv:1404.1100},
  eprint = {1404.1100},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-02-11},
  abstract = {Principal component analysis (PCA) is a mainstay of modern data analysis - a black box that is widely used but (sometimes) poorly understood. The goal of this paper is to dispel the magic behind this black box. This manuscript focuses on building a solid intuition for how and why principal component analysis works. This manuscript crystallizes this knowledge by deriving from simple intuitions, the mathematics behind PCA. This tutorial does not shy away from explaining the ideas informally, nor does it shy away from the mathematics. The hope is that by addressing both aspects, readers of all levels will be able to gain a better understanding of PCA as well as the when, the how and the why of applying this technique.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,PCA,Statistics - Machine Learning},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\C2N27AXA\\Shlens - 2014 - A Tutorial on Principal Component Analysis.pdf;C\:\\Users\\zoona\\Zotero\\storage\\FBKCNXYQ\\1404.html}
}

@article{sterneMultipleImputationMissing2009,
  title = {Multiple Imputation for Missing Data in Epidemiological and Clinical Research: Potential and Pitfalls},
  shorttitle = {Multiple Imputation for Missing Data in Epidemiological and Clinical Research},
  author = {Sterne, Jonathan A. C. and White, Ian R. and Carlin, John B. and Spratt, Michael and Royston, Patrick and Kenward, Michael G. and Wood, Angela M. and Carpenter, James R.},
  year = {2009},
  month = jun,
  journal = {BMJ},
  volume = {338},
  pages = {b2393},
  publisher = {{British Medical Journal Publishing Group}},
  issn = {0959-8138, 1468-5833},
  doi = {10.1136/bmj.b2393},
  urldate = {2023-04-18},
  abstract = {{$<$}p{$>$}Most studies have some missing data. \textbf{Jonathan Sterne and colleagues} describe the appropriate use and reporting of the multiple imputation approach to dealing with them {$<$}/p{$>$}},
  chapter = {Research Methods \&amp; Reporting},
  copyright = {\textcopyright{}  . This is an open-access article distributed under the terms of the Creative Commons Attribution Non-commercial License, which permits use, distribution, and reproduction in any medium, provided the original work is properly cited, the use is non commercial and is otherwise in compliance with the license. See: http://creativecommons.org/licenses/by-nc/2.0/  and  http://creativecommons.org/licenses/by-nc/2.0/legalcode.},
  langid = {english},
  pmid = {19564179},
  keywords = {epidemiological,imputation,Missing data},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\UC3AMSUS\\Sterne et al. - 2009 - Multiple imputation for missing data in epidemiolo.pdf;C\:\\Users\\zoona\\Zotero\\storage\\M8N9LCWE\\bmj.html}
}

@book{sweigartAutomateBoringStuff2019,
  title = {Automate {{The Boring Stuff With Python}}, 2nd {{Edition}}},
  author = {Sweigart, Al},
  year = {2019},
  month = nov,
  publisher = {{No Starch Press,US}},
  address = {{San Francisco}},
  isbn = {978-1-59327-992-9}
}

@misc{SystemDesignFundamentals,
  title = {System Design Fundamentals: {{What}} Is the {{CAP}} Theorem?},
  shorttitle = {System Design Fundamentals},
  journal = {Educative: Interactive Courses for Software Developers},
  urldate = {2023-02-11},
  abstract = {Today, we'll dive deeper into the CAP theorem, explaining its meaning, its components, and more.},
  howpublished = {https://www.educative.io/blog/what-is-cap-theorem\#whatiscaptheorem},
  langid = {english},
  keywords = {CAP theorem},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\VPM8GJ2W\\what-is-cap-theorem.html}
}

@book{tabachnickUsingMultivariateStatistics2014,
  title = {Using Multivariate Statistics},
  author = {Tabachnick, Barbara G. and Fidell, Linda S.},
  year = {2014},
  edition = {Sixth edition},
  publisher = {{Pearson}},
  address = {{Harlow, Essex}},
  isbn = {978-1-292-02131-7}
}

@misc{TryJupyterWebbased,
  title = {Try {{Jupyter}}! {{Web-based Notebook}}},
  howpublished = {https://try.jupyter.org/}
}

@book{vanderplasPythonDataScience2016,
  title = {Python Data Science Handbook: Essential Tools for Working with Data},
  author = {Vanderplas, Jacob T.},
  year = {2016},
  edition = {First edition},
  publisher = {{O'Reilly Media, Inc}},
  address = {{Sebastopol, CA}},
  isbn = {1-4919-1214-6}
}

@book{weiCorrplotVisualizationCorrelation2021,
  title = {Corrplot: {{Visualization}} of a {{Correlation Matrix}}},
  author = {Wei, Taiyun and Simko, Viliam},
  year = {2021}
}

@book{weiCorrplotVisualizationCorrelation2021a,
  title = {Corrplot: {{Visualization}} of a {{Correlation Matrix}}},
  author = {Wei, Taiyun and Simko, Viliam},
  year = {2021}
}

@book{weiPackageCorrplotVisualization2021,
  title = {R Package 'Corrplot': {{Visualization}} of a {{Correlation Matrix}}},
  author = {Wei, Taiyun and Simko, Viliam},
  year = {2021}
}

@book{weiPackageCorrplotVisualization2021a,
  title = {R Package 'Corrplot': {{Visualization}} of a {{Correlation Matrix}}},
  author = {Wei, Taiyun and Simko, Viliam},
  year = {2021}
}

@misc{WhatAnacondaAnaconda,
  title = {What Is {{Anaconda}}? | {{Anaconda}}},
  howpublished = {https://www.anaconda.com/what-is-anaconda/}
}

@book{wickhamGgplot2CreateElegant2022,
  title = {Ggplot2: {{Create Elegant Data Visualisations Using}} the {{Grammar}} of {{Graphics}}},
  author = {Wickham, Hadley and Chang, Winston and Henry, Lionel and Pedersen, Thomas Lin and Takahashi, Kohske and Wilke, Claus and Woo, Kara and Yutani, Hiroaki and Dunnington, Dewey},
  year = {2022}
}

@book{wickhamGgplot2CreateElegant2022a,
  title = {Ggplot2: {{Create Elegant Data Visualisations Using}} the {{Grammar}} of {{Graphics}}},
  author = {Wickham, Hadley and Chang, Winston and Henry, Lionel and Pedersen, Thomas Lin and Takahashi, Kohske and Wilke, Claus and Woo, Kara and Yutani, Hiroaki and Dunnington, Dewey},
  year = {2022}
}

@book{wickhamGgplot2ElegantGraphics,
  title = {Ggplot2: {{Elegant Graphics}} for {{Data Analysis}}},
  author = {Wickham, Hadley and Navarro, Danielle and Pedersen, Thomas Lin},
  edition = {work-in-progress 3rd edition}
}

@book{wickhamGgplot2ElegantGraphics2016,
  title = {Ggplot2: {{Elegant Graphics}} for {{Data Analysis}}},
  author = {Wickham, Hadley},
  year = {2016},
  publisher = {{Springer-Verlag New York}},
  isbn = {978-3-319-24277-4}
}

@book{wickhamGgplot2ElegantGraphics2016a,
  title = {Ggplot2: {{Elegant Graphics}} for {{Data Analysis}}},
  author = {Wickham, Hadley},
  year = {2016},
  publisher = {{Springer-Verlag New York}},
  isbn = {978-3-319-24277-4}
}

@book{wilkeFundamentalsDataVisualization,
  title = {Fundamentals of {{Data Visualization}}},
  author = {Wilke, Claus O.},
  urldate = {2023-02-11},
  abstract = {A guide to making visualizations that accurately reflect the data, tell a story, and look professional.},
  keywords = {Data Visualisation,R},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\TVARL3EF\\dataviz.html}
}

@article{yongBeginnerGuideFactor2013,
  title = {A {{Beginner}}'s {{Guide}} to {{Factor Analysis}}: {{Focusing}} on {{Exploratory Factor Analysis}}},
  shorttitle = {A {{Beginner}}'s {{Guide}} to {{Factor Analysis}}},
  author = {Yong, An Gie and Pearce, Sean},
  year = {2013},
  month = oct,
  journal = {Tutorials in Quantitative Methods for Psychology},
  volume = {9},
  number = {2},
  pages = {79--94},
  issn = {1913-4126},
  doi = {10.20982/tqmp.09.2.p079},
  urldate = {2023-02-11},
  langid = {english},
  keywords = {EFA,Factor Analysis},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\UJDJIEPK\\Yong and Pearce - 2013 - A Beginner’s Guide to Factor Analysis Focusing on.pdf}
}

@misc{zotero-116,
  urldate = {2023-02-17},
  howpublished = {https://probml.github.io/pml-book/book1.html},
  file = {C\:\\Users\\zoona\\Zotero\\storage\\TQCFQEC8\\book1.html}
}

@misc{zotero-243,
  type = {Misc}
}
